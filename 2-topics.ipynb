{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 4: Topic modeling\n",
    "\n",
    "Use topic models to explore hotel reviews\n",
    "\n",
    "Objectives:\n",
    "* tokenize with MWEs using spacy\n",
    "* estimate LDA topic models with tomotopy\n",
    "* visualize and evaluate topic models\n",
    "* apply topic models to interpretation of hotel reviews\n",
    "\n",
    "## Build topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in hotel review data and tokenize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('hotels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import MWETokenizer\n",
    "\n",
    "tokenizer = MWETokenizer(open('hotel-terms.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a sample of reviews to work with (replace x's below with the sample size; you should use at least 50,000 reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = df.sample(xxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf['tokens'] = pd.Series(subdf['text'].progress_apply(tokenizer.tokenize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the model **hyperparameters**: aspects of the model that aren't estimated from the data but have to be set in advance by the analyst. There's no \"right\" values for these. You'll just have to try out different values to find settings that give you a model that you can interpret:\n",
    "\n",
    "* *k* = number of topics\n",
    "* *min_df* = minimum number of reviews that a term has to occur in to be included in the model\n",
    "* *rm_top* = number of most frequent terms to remove from the model\n",
    "* *tw* = term weighting strategy (described [here](https://bab2min.github.io/tomotopy/v0.10.1/en/#tomotopy.TermWeight)]\n",
    "* *alpha*, *eta* = priors for document-topic and topic-word distributions\n",
    "* *tol* = convergence tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "min_df = 100\n",
    "rm_top = 75\n",
    "tw = tp.TermWeight.ONE\n",
    "alpha = 0.1\n",
    "eta = 0.01\n",
    "tol = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where we do the inference. The documentation for `LDAModel` is [here](https://bab2min.github.io/tomotopy/v0.10.1/en/#tomotopy.LDAModel). You might also consider trying out one of the other model types (e.g., `HDPModel`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mdl = tp.LDAModel(k=k, min_df=min_df, rm_top=rm_top, tw=tw, alpha=alpha, eta=eta)\n",
    "\n",
    "for doc in subdf['tokens']:\n",
    "    if doc:\n",
    "        mdl.add_doc(doc)\n",
    "\n",
    "last = np.NINF\n",
    "for i in range(0, 5000, 50):\n",
    "    mdl.train(50)\n",
    "    ll = mdl.ll_per_word\n",
    "    print(f'{i:5d} LL = {ll:7.4f}', flush=True)\n",
    "    if ll - last < tol:\n",
    "        break\n",
    "    else:\n",
    "        last = ll\n",
    "\n",
    "print(f'Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What terms are associated with each topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(mdl.k):\n",
    "    print(f'{k:3d} ', ', '.join(s for s,_ in mdl.get_topic_words(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which terms got remove due to `rm_top`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(mdl.removed_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize topic model with LDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "topic_term_dists = np.stack([mdl.get_topic_word_dist(k)\n",
    "                             for k in range(mdl.k)])\n",
    "doc_topic_dists = np.stack([doc.get_topic_dist() for doc in mdl.docs])\n",
    "doc_lengths = np.array([len(doc.words) for doc in mdl.docs])\n",
    "vocab = list(mdl.used_vocabs)\n",
    "term_frequency = mdl.used_vocab_freq\n",
    "prepared_data = pyLDAvis.prepare(topic_term_dists,\n",
    "                                 doc_topic_dists,\n",
    "                                 doc_lengths,\n",
    "                                 vocab,\n",
    "                                 term_frequency, \n",
    "                                 mds='tsne', \n",
    "                                 sort_topics=False\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(prepared_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find documents that best represent each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(np.argmax(doc_topic_dists, axis=0)):\n",
    "    print(i, ', '.join(map(first, mdl.get_topic_words(i))))\n",
    "    print(subdf['text'].iloc[d])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate word clouds for topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "freqs = dict(mdl.get_topic_words(54, 200))\n",
    "wc = WordCloud(width=1000,height=1000,background_color='white').generate_from_frequencies(freqs)\n",
    "plt.axis('off')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final, best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.save('hotel-topics.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
